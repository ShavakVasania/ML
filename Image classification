import pickle
import numpy as np
from PIL import Image
from numpy import reshape, transpose
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import MaxPooling2D, Conv2D, Flatten, Dense, Activation, Dropout
from keras.callbacks import EarlyStopping
from tensorflow.keras import metrics

def unpickle(file):
    with open(file, 'rb') as fo:
        myDict = pickle.load(fo, encoding='latin1')
    return myDict

# load data
train = unpickle("/workspaces/ShavakVasania/cifar-10-batches-py/data_batch_1")
test = unpickle("/workspaces/ShavakVasania/cifar-10-batches-py/test_batch")
meta = unpickle("/workspaces/ShavakVasania/cifar-10-batches-py/batches.meta")
x_train = train["data"]
x_test = test["data"]
y_train = train["labels"]
y_test = test["labels"]

#normalize numerical data and one hot encode labels
x_train = x_train.astype('float32')/255
x_test = x_test.astype('float32')/255
y_train = to_categorical(y_train, num_classes=10)
y_test = to_categorical(y_test,num_classes=10)

#reshape input image data into correct format for CNN
x_train = x_train.reshape((10000,3,32,32)).transpose(0,2,3,1)
x_test = x_test.reshape((10000,3,32,32)).transpose(0,2,3,1)

#softmax final layer produces probabily score for each class
model = Sequential([
    Conv2D(32, kernel_size=3, padding='same',activation='relu', input_shape=(32,32,3)),
    MaxPooling2D(pool_size = 2),
    Conv2D(64, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size = 2),
    Conv2D(64, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size = 2),
    Conv2D(64, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size = 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(10, activation='softmax')
])
#stop fitting after 5 epochs of no improvement
cbs = [EarlyStopping(patience=5, restore_best_weights=True)]

#categorical crossentropy loss used as it is a multiple classification problem
model.compile(loss='categorical_crossentropy',
                optimizer='Adam',
                metrics=['accuracy'])
                
#fit training data to model
model.fit(x_train, 
           y_train,
           batch_size=64,
           epochs=50,
           validation_split=0.2,
           callbacks=cbs)

#get accuracy on new test data
y_pred = model.predict(x_test)
accuracy = metrics.Accuracy()
accuracy.update_state(y_test y_pred)
print("Accuracy: {:.2f}%".format(accuracy.result() * 100))
